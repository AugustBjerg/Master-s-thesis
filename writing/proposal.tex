\documentclass[12pt,onecolumn]{article}

\usepackage[a4paper, margin=1in]{geometry}
\usepackage{mathptmx}  % Times Roman with math support
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{url}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{textgreek}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{placeins,needspace}
\usepackage{adjustbox}
\usepackage{parskip} % Better spacing between paragraphs
\usepackage{lipsum}
\usepackage{xcolor}
\usepackage{setspace} % Makes linespacing possible


\captionsetup[table]{font=tiny,justification=centering,position=bottom}

\doublespacing % \setstretch{1.2} for custom, you can also do single or double spacing

\definecolor{mydarkgray}{gray}{0.2}


\usepackage[style=apa, backend=biber]{biblatex}
\DeclareLanguageMapping{english}{english-apa}
\addbibresource{references/proposal.bib}  

% Customize section title appearance
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\title{\textbf{[Exploring Data-Driven Approaches to Identifying Sources of Operational Efficiency in Maritime Transport]}}
\author{
August Bjerg-Heise (114300315)
}
\date{31 December 2025}
\vspace{1em}


\begin{document}

% ----- Front Page -----
\begin{titlepage}
    \centering
    \vspace*{2cm}

    \textbf{\Large{Research Proposal}}\\[1em]
    \textbf{\Huge{Identifying Sources of Operational Efficiency in Maritime Transport}}\\[3em]

    % Placeholder for Image
    % \includegraphics[width=0.6\textwidth]{your_image.png}\\[3em]

    \begin{center}
    \textbf{Student:} August Bjerg-Heise (114300315)\\[1.2em]
    \textbf{Date of Submission:} January 1st, 2025\\[1.2em]
    % TODO: update page count before hand-in
    \textbf{Number of Pages:} 10\\[1.2em]
    \end{center}

\end{titlepage}
\clearpage

\section{Introduction}

The operational efficiency of a vessel can largely be defined as its ability to achieve the highest transport work for the lowest fuel consumption. (source)

With maritime transport constituting 3\% of global CO2 emissions, this is a pressing issue that goes beyond the shipping industry
% Comment on the magnitude of the problem (Shipping -> x% of global emissions / equal to X country -> fuel x% of shipping emissions -> decreasing fuel use by x% would be equivalent to decarbonising the entire (X country, maybe Taiwan))

% Include a comment on the scope of the proposal (e.g., not to evaluate new tech or retrofittings)

% Include RQs:

\section{Literature Review}

Ever since the first ships were built, operators have sought to optimize energy use, first in manpower and wind, and later in modern fuels. The earliest academic contributions are commonly traced to 19th-century work on the physics of ship resistance and propulsion \parencite{Russell1839Experimental}, alongside the pioneering of systematic towing-test approaches that enabled empirical inference about performance \parencite{froude1955papers}. This early literature cemented a central operational hypothesis: efficiency is governed primarily by the relationship between speed and required propulsive power, a principle embedded today in the “speed–power curve,” which maps the power needed to maintain each steady speed under specified conditions. Through almost two centuries of research, it has been found that the relationship between speed and propulsion power is approximately cubic, i.e., power need rises steeply with speed (see example in Figure \ref{fig:example_spd_pwr_curve}). 

\begin{figure}[htbp]
   \centering
   \captionsetup{font=scriptsize,justification=centering}
   \includegraphics[width=0.65\linewidth]{figures/proposal/example_spd_pwr_curve.png}
   \caption{Example of a speed-power curve derived from empirical tests \parencite{Schultz2007EffectsOfCoating}}
   \label{fig:example_spd_pwr_curve}
\end{figure}

As measurement and computation matured, subsequent research increasingly combined physics-grounded models with real operational data, enabling more mathematically complex and empirically testable approaches to operational efficiency analysis \parencite{kim2025comprehensive}. More contemporary work can be grouped into three broad methodological categories: i) Computational Fluid Dynamics, ii) Empirical Naval Architecture and iii) Data Science.

Computational fluid dynamics (CFD) is a physics-based approach that numerically solves the flow equations around a ship hull to predict resistance and related propulsion requirements as a function of speed and operating conditions \parencite{Russell1839Experimental}. Conceptually, this computational programme extends early resistance-focused science, including Russell’s experimental work that treated resistance as a mechanistic phenomenon. Contemporary studies broaden the optimization target from calm-water performance to operational conditions, for example panel-method modelling of wave added resistance and related wave-load computations that refine how power penalties are represented under realistic sea states \parencite{Dong_2023,Wang_2022}. Relative to purely empirical curves and data-driven models, CFD’s key strengths are physical interpretability and theoretical rigor, while its main limitations remain sensitivity to modelling assumptions and the need for careful verification and validation, alongside high computational cost.

Empirical naval architecture (ENA) models estimate the speed–power relationship from physical measurements, most commonly towing-tank tests where a scale model is towed at controlled speeds and resistance is measured for inference. In contrast to CFD, which derives the same relationship by numerically solving flow equations, towing tests provide benchmark data that is often used to validate and calibrate computational predictions. This experimental tradition is commonly linked to William Froude and Robert Froude’s \parencite*{froude1955papers} development of systematic model testing and scaling concepts for predicting full-scale ship performance. More recent applications include towing-tank studies of operational interventions such as hull coatings \parencite{Schultz2007EffectsOfCoating}, while the core trade-off remains that experiments can be highly accurate under controlled conditions but are expensive, time-consuming, and not always fully representative of real sea states and in-service hull condition.

Data-science approaches model operational efficiency directly from observed data, typically without imposing any physical constraints. However, physics-informed feature choice and engineering remain necessary to avoid spurious inference. Recent work leverages increasingly dense IoT (sensor) data streams to estimate performance baselines and degradation signals, for example by building data-driven digital twins that predict “expected” speed and then interpret systematic deviations as fouling-induced speed loss \parencite{Coraddu2019}. Related studies fuse operational logs with metocean data and apply machine-learning regressors to quantify hull condition, enabling counterfactual evaluation of cleaning timing under controlled operating scenarios \parencite{Duan2024}. The main strength of these methods is flexibility in capturing ship-specific, nonlinear relationships at scale as data availability and ML toolchains have improved, but their central limitation is dependence of very high volume, frequency and quality of data \parencite{kim2025comprehensive}. From a research perspective, exploring new avenues within data-science based approaches is a particularly interesting due to the recent rapid developments in the quantity and quality of data.

\section{Theoretical Framework (1.5 pages)}

1: Some ship specifics?
2: Data-science based approach to identify sources of inefficiency

\subsection{Hypotheses}

\section{Dataset (1 page)}
\subsection{Origin}

\subsection{Ship particulars}

\subsection{Contents}

\section{Methodology}

\label{sec:modelling_framework}
\subsection{Modelling framework}

It is intended to use statistical modelling to separate an estimated “optimal” operating speed from observed performance. First, an “optimal-speed” benchmark will be constructed by fitting a predictive model of vessel speed using data from a period in which operation can reasonably be assumed close to optimal, such as the first month following a hull and propeller cleaning event. This benchmark model will then be used to compute speed loss at each operating point as the difference between predicted optimal speed and observed speed. Second, a separate explanatory model will be estimated on data from a later, non-optimal period, in which fouling, engine depreciation, and other degradation mechanisms are expected to be present, with the dependent variable defined as the estimated speed loss and the regressors given by operational and environmental covariates in the dataset. The latter will be built for an inferential purpose, i.e., the primary purpose will be to deconstruct to infer what variables led to a given prediction. This will allow for the attribution of developments in inefficiency to certain variables and, in extension, parts of the ship. The approach to modelling is shown in \ref{fig:outdated_approach_viz}.
    
\begin{figure}[htbp]
   \centering
   \captionsetup{font=scriptsize,justification=centering}
   \includegraphics[width=0.85\linewidth]{figures/proposal/outdated_approach_viz.png}
   \caption{Visualisation of approach}
   \label{fig:outdated_approach_viz}
\end{figure}

\subsection{models}

To predict the speed loss, It is suggested to employ and compare multiple models of varying complexity for two reasons. Firstly, it increases the likelihood of achieving a satisfactory predictive power. Secondly, it allows for the evaluation of the accuracy/complexity trade-off which is particularly relevant in edge computing scenarios such as onboard deployment. Applying three different models are suggested as a starting point. As a simple baseline model, it is suggested to use a linear regression due to its simplicity and intuitive interpretation of coefficients. As a natural progression of complexity, it is suggested to use a decision tree since it can model more complex relationships while still staying relatively interpretable. Lastly, it is suggested to include neural network-based model to have a high complexity benchmark to inform the complexity/trade-off analysis. For the latter two model choices is suggested to use SHapley Additive exPlanations (SHAP) values for attribution. The best predictive model should be chosen for a inferential analysis as described in \ref{sec:modelling_framework}. It is suggested to take an experimental approach and also look into other models to find the best model.

\section{Expected Results and Applications (1.5 page)}

\clearpage

\printbibliography

\clearpage
\appendix

\section*{Appendix}
\addcontentsline{toc}{section}{Appendix}

% Make appendix sections use Arabic numbers instead of letters:
\renewcommand{\thesection}{\arabic{section}}
\setcounter{section}{0}

\section{[Appendix Section Title]}
\label{sec:appendix1}

[Your appendix content goes here.]

% Example of appendix figure
% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.8\linewidth]{appendix_figure.png}
%   \caption{Your appendix figure caption}
%   \label{fig:appendix_label}
% \end{figure}

\end{document}
